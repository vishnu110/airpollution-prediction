# -*- coding: utf-8 -*-
"""LSTM SOURCE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17UcCAMh9mf0XMKJ-jd_6Gxx8UEbY80v1
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

df = pd.read_csv('/content/processed.csv')
df['Date'] = pd.to_datetime(df['Date'], format="%d-%m-%Y")
print(df['Date'].dtype)
df.index = df['Date']
df.drop('Date', axis=1, inplace=True)

df

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df)

# Convert the dataframe to numpy array
data = scaled_data

# Define the percentage of the dataset to be used for training
training_data_len = int(np.ceil(len(data) * 0.8))

# Create the training data
train_data = data[0:training_data_len, :]

# Split the data into x_train and y_train
x_train = []
y_train = []

for i in range(80, len(train_data)):
    x_train.append(train_data[i-80:i, :])
    y_train.append(train_data[i, :])

# Convert x_train and y_train to numpy arrays
x_train, y_train = np.array(x_train), np.array(y_train)

# Create the test data
test_data = data[training_data_len - 80:, :]

# Split the data into x_test and y_test
x_test = []
y_test = data[training_data_len:, :]

for i in range(60, len(test_data)):
    x_test.append(test_data[i-80:i, :])

# Convert x_test to numpy arrays
x_test = np.array(x_test)

from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=100, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=100, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=100))
model.add(Dropout(0.2))
model.add(Dense(units=50))
model.add(Dense(units=8))  # 8 output features

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Get the predicted scaled values
predictions = model.predict(x_test)

# Unscale the predicted values
predictions = scaler.inverse_transform(predictions)

# Unscale the true values
y_test = scaler.inverse_transform(y_test)

# prompt: accuracy of all 8 columns

from sklearn.metrics import mean_absolute_percentage_error
accuracy_scores = []
for i in range(8):
    accuracy = 100 - mean_absolute_percentage_error(y_test[:, i], predictions[:, i])
    accuracy_scores.append(accuracy)

for i, column in enumerate(df.columns):
    print(f"Accuracy for {column}: {accuracy_scores[i]:.2f}%")

# plot for all 8 parameter  as all accuracy above 90 the the graph should overlap actual and accuracy were x axis is date and y axis is value  total 8 plots

# Plot for all 8 parameters
fig, axes = plt.subplots(4, 2, figsize=(15, 15))
axes = axes.flatten()

for i, column in enumerate(df.columns):
    # Plot the actual and predicted values
    axes[i].plot(y_test[:, i], label='Actual', color='blue')
    axes[i].plot(predictions[:, i], label='Predicted', color='orange')

    # Set the title and labels
    axes[i].set_title(f'{column} Prediction')
    axes[i].set_xlabel('Date')
    axes[i].set_ylabel(column)

    # Add legend and grid
    axes[i].legend()
    axes[i].grid(True)

# Adjust the spacing between subplots
plt.tight_layout()

# Show the plot
plt.show()

# Prepare the last 60 days of data for prediction
last_60_days = data[-60:]

# Create an empty list to store the predictions
future_predictions = []

# Predict the next 30 days
for i in range(30):
    # Prepare the input data for prediction
    input_data = last_60_days[-60:]
    input_data = input_data.reshape((1, 60, input_data.shape[1]))

    # Make the prediction
    pred = model.predict(input_data)
    future_predictions.append(pred)

    # Append the prediction to the input data
    last_60_days = np.append(last_60_days, pred, axis=0)

# Convert the predictions to the original scale
future_predictions = np.array(future_predictions)
future_predictions = scaler.inverse_transform(future_predictions.reshape(-1, 8))

# Create a DataFrame for the predictions
future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=30)
future_df = pd.DataFrame(future_predictions, index=future_dates, columns=df.columns)

# Display the future predictions
print(future_df)

# prompt: # Display the future predictions
# print(future_df)  in a table

print(future_df.to_string())

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Calculate the evaluation metrics for all 9 columns
for i in range(8):
    mae = mean_absolute_error(y_test[:, i], predictions[:, i])
    mse = mean_squared_error(y_test[:, i], predictions[:, i])
    rmse = np.sqrt(mse)
    print(f"Column: {df.columns[i]}")
    print("Mean Absolute Error (MAE):", mae)
    print("Mean Squared Error (MSE):", mse)
    print("Root Mean Squared Error (RMSE):", rmse)
    print()